{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing tables\n",
    "def printTable(header, data):\n",
    "    \"\"\"\n",
    "    Prints table with columns of header and data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    header : []\n",
    "        list of header labels\n",
    "        ex. header = [\"one\",\"two\",\"three\"]\n",
    "    data : [[],[],...,[]]\n",
    "        list of lists, each inner list is a data line\n",
    "        data line must index with header appropriately\n",
    "        ex. data = [[1, 2, 3],[1, 2, 3]]\n",
    "    \"\"\"\n",
    "    \n",
    "    # print headers\n",
    "    col_widths=[]\n",
    "    for i,label in enumerate(header):\n",
    "        col_widths.append(len(label))\n",
    "        if i == 0 :\n",
    "            print(\"| \",end=\"\")\n",
    "        print(str(label).center(len(label)), end=\" | \")\n",
    "    print()\n",
    "    \n",
    "    # print separating line\n",
    "    for i,width in enumerate(col_widths):\n",
    "        if i == 0 :\n",
    "            print(\"| \",end=\"\")\n",
    "        print(\"\".center(width,\"-\"), end=\" | \")\n",
    "    print()\n",
    "    \n",
    "    # print data\n",
    "    for i,line in enumerate(data):\n",
    "        for i,value in enumerate(line):\n",
    "            if i == 0 :\n",
    "                print(\"| \",end=\"\")\n",
    "            print(str(value).center(col_widths[i]), end=\" | \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r', 'g', 'b']\n",
    "\n",
    "# Define three cluster centers\n",
    "centers = [[4, 1],\n",
    "           [1, 7],\n",
    "           [5, 6]]\n",
    "\n",
    "# Define three cluster sigmas in x and y, respectively\n",
    "sigmas = [[0.8, 0.5],\n",
    "          [0.5, 1.1],\n",
    "          [0.7, 0.7]]\n",
    "\n",
    "# seeded for reproducibility\n",
    "np.random.seed(2)  \n",
    "\n",
    "# Initial varables\n",
    "xpts = np.zeros(1)\n",
    "ypts = np.zeros(1)\n",
    "labels = np.zeros(1)\n",
    "\n",
    "# Zip object is an iterator of tuples, enumerate returns centers: sigmas pair\n",
    "# Total of 200 sample points, in 3 clusters\n",
    "for i, ((x_center, y_center), (x_sigma, y_sigma)) in enumerate(zip(centers, sigmas)):\n",
    "    # Create row array x or y value of each point\n",
    "    xpts = np.hstack((xpts, np.random.standard_normal(200) * x_sigma + x_center))\n",
    "    ypts = np.hstack((ypts, np.random.standard_normal(200) * y_sigma + y_center))\n",
    "    labels = np.hstack((labels, np.ones(200) * i))\n",
    "\n",
    "\n",
    "# Remove the extra 0 at front \n",
    "xpts = np.delete(xpts,0)\n",
    "ypts = np.delete(ypts,0)\n",
    "labels = np.delete(labels,0)\n",
    "\n",
    "# Visualize the test data\n",
    "for j in range(3):\n",
    "    plt.plot(xpts[j == labels],ypts[j==labels],'.', color = colors[j], label = 'Class %s'%j)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Sample 2 feature input with 3 classes')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "xy = np.vstack((xpts,ypts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep simple data in format two columns = two features = two axis\n",
    "X = xy.transpose()\n",
    "b = labels.transpose()\n",
    "\n",
    "# model parameters\n",
    "num_samples = len(b)\n",
    "X_svm = np.hstack((X, np.ones((num_samples, 1))))\n",
    "num_features = len(X[0])\n",
    "w_k = np.zeros((num_features+1, 1))\n",
    "\n",
    "r = 0.1 # regularizer (aka lambda)\n",
    "U, s, V = np.linalg.svd(X_svm)\n",
    "tau = 1/s[0]**2 # max stepsize\n",
    "#print(\"Step size tau: {:0.10f}\".format(tau))\n",
    "\n",
    "# loop through each class\n",
    "classes = [0,1,2]\n",
    "b_classes = np.zeros((len(b),len(classes)))\n",
    "b_test_svm = np.zeros(b_classes.shape)\n",
    "w_svm = np.zeros((len(w_k),len(classes)))\n",
    "descent_done = False\n",
    "for c in classes:\n",
    "    \n",
    "    # form binary labels, assign +1 to one class, -1 to all others\n",
    "    b_svm = np.where(b == c, 1, -1)\n",
    "    b_classes[:,c] = b_svm.reshape(len(b_svm))\n",
    "    last_loss = 100000000000000.\n",
    "    descent_done = False\n",
    "    # train svm\n",
    "    num_steps = 50000\n",
    "    iterations= 0\n",
    "        \n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "\n",
    "    while not descent_done:\n",
    "        loss = 0\n",
    "        # loop through training samples\n",
    "        l_hinge = np.zeros(w_k.shape)\n",
    "        for s in range(num_samples):\n",
    "            # indicator function\n",
    "            counter2 +=1\n",
    "            if b_svm[s]*X_svm[s]@w_k < 1:\n",
    "                counter +=1\n",
    "                loss += (1-b_svm[s]*X_svm[s]@w_k)\n",
    "                l_hinge = np.add(l_hinge, -b_svm[s]*X_svm[s].reshape(l_hinge.shape))\n",
    "\n",
    "        # comapre loss to determine if reached minimum\n",
    "        if(last_loss < loss):\n",
    "            print(\"After %d itrations, reached bottom of valley\" %iterations)\n",
    "            #print(w_k)\n",
    "            descent_done = True\n",
    "        #update for next iteration\n",
    "        w_k = w_k - tau*(l_hinge+2*r*w_k)\n",
    "        last_loss = loss\n",
    "        iterations +=1\n",
    "      \n",
    "    # save weights\n",
    "    w_svm[:,c] = w_k.reshape(len(w_k)) # svm\n",
    "    \n",
    "    # 2D Graph of seperated data\n",
    "    fig = plt.figure()\n",
    "    plt.plot(X[(c==b),0],X[(c==b),1],'.', color = 'r', label = 'Postive Class')\n",
    "    plt.plot(X[(c!=b),0],X[(c!=b),1],'.', color = 'grey', label = 'Negative Class')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('OvA with Class %s Positive, all other Negative'%c)\n",
    "    \n",
    "    # SVM bounds plot\n",
    "    plot_bounds = [0.5, 6.5]\n",
    "    db = [svm_contour(plot_bounds[0], w_k, 0), svm_contour(plot_bounds[1], w_k, 0)] \n",
    "    db_pos1 = [svm_contour(plot_bounds[0], w_k, 1.), svm_contour(plot_bounds[1], w_k, 1.)] \n",
    "    db_neg1 = [svm_contour(plot_bounds[0], w_k, -1.), svm_contour(plot_bounds[1], w_k, -1.)] \n",
    "    plt.plot(plot_bounds,db, color=\"green\", label=\"decision boundary\")\n",
    "    plt.plot(plot_bounds,db_pos1, color=\"green\", linestyle=\"--\", label=\"support vector\")\n",
    "    plt.plot(plot_bounds,db_neg1, color=\"green\", linestyle=\"--\")\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1.0))\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test svm against known training data\n",
    "header = [\"class\", \"  svm  \"]\n",
    "data = []\n",
    "for c in classes:\n",
    "    b_hat_svm = X_svm@w_svm[:,c]\n",
    "    b_test_svm[:,c] = b_hat_svm.reshape(len(b))\n",
    "\n",
    "    # find percent incorrect\n",
    "    num_incorrect_svm = np.sum(np.sign(b_test_svm[:,c]) != b_classes[:,c])\n",
    "    percent_incorrect_svm = num_incorrect_svm/len(b)*100\n",
    "    data.append([c,\"{:0.2f} %\".format(percent_incorrect_svm)])\n",
    "    \n",
    "printTable(header,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeded random ensures reproducibility\n",
    "np.random.seed(6)\n",
    "# randomly generate 10 points for testing purpose\n",
    "sampleNum = 10\n",
    "X_testing = np.random.rand(sampleNum,2)\n",
    "X_testing = np.multiply(X_testing, [8,10])\n",
    "X_testing = np.hstack((X_testing, np.ones((sampleNum, 1))))\n",
    "Y_testing = np.ndarray((3,1))\n",
    "count_per_class = np.ndarray((num_samples,3))\n",
    "for j in range(3):\n",
    "    plt.plot(xpts[j == labels],ypts[j==labels],'.', color = colors[j], label = 'Class %s training'%j)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('OvA Testing')\n",
    "plt.plot(X_testing[:,0],X_testing[:,1],'x', color = 'fuchsia', label = 'Testing set')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()\n",
    "print(\"The Class with highest probability after applying to the three binary classifiers wins\")\n",
    "for c in classes:\n",
    "    count = np.sum(X_testing@w_svm[:,c] > 0)\n",
    "    print(\"Class {} probability: {}\".format(c, count/sampleNum) )\n",
    "    Y_testing[c] = count\n",
    "\n",
    "print(\"This testing set predected as class %d\"%np.argmax(Y_testing))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
